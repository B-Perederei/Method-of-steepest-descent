{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "np.set_printoptions(precision=128)\n",
    "\n",
    "functionCalculated = 0\n",
    "\n",
    "def f(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    global functionCalculated\n",
    "    functionCalculated += 1\n",
    "    return x1**2 + x2**2\n",
    "    # return (x1-1)**2 + (x2-1)**2\n",
    "    # return 100 * (x1**2-x2)**2 + (x1-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{h}, {h*np.array([1, 0])}, {h*np.array([0, 1])}\")\n",
    "def fderright(x, fx, h):\n",
    "    gradFx1 = (f(x + h*np.array([1, 0])) - fx) / h\n",
    "    gradFx2 = (f(x + h*np.array([0, 1])) - fx) / h\n",
    "    return np.array([gradFx1, gradFx2])\n",
    "\n",
    "def fderleft(x, fx, h):\n",
    "    gradFx1 = (fx - f(x - h*np.array([1, 0]))) / h\n",
    "    gradFx2 = (fx - f(x - h*np.array([0, 1]))) / h\n",
    "    return np.array([gradFx1, gradFx2])\n",
    "\n",
    "def fdercenter(x, h):\n",
    "    gradFx1 = (f(x + h*np.array([1, 0])) - f(x - h*np.array([1, 0]))) / (2*h)\n",
    "    gradFx2 = (f(x + h*np.array([0, 1])) - f(x - h*np.array([0, 1]))) / (2*h)\n",
    "    return np.array([gradFx1, gradFx2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    return math.sqrt(x1**2 + x2**2)\n",
    "\n",
    "def stopCriteria1(xk, fxk, xk_1, fxk_1, e):\n",
    "    if ((norm((xk_1 - xk)) / norm(xk)) <= e) and (math.fabs(fxk_1 - fxk) <= e):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def stopCriteria2(gradFxk, e):\n",
    "    if (norm(gradFxk) <= e):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for finding optimal Lambda\n",
    "functionCalculatedForLambda = 0\n",
    "\n",
    "svenCoefLambda = 1\n",
    "l0 = 0\n",
    "\n",
    "eGoldenCut = 0.01\n",
    "\n",
    "'''\n",
    "def f(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    return 3*(x1-15)**2 -x1*x2 +4*x2**2\n",
    "'''\n",
    "\n",
    "def FLambda(xk, l, Sk):\n",
    "    global functionCalculatedForLambda\n",
    "    functionCalculatedForLambda += 1\n",
    "    return f(xk + l*Sk)\n",
    "\n",
    "def sven(xk, Sk):\n",
    "    deltaL = svenCoefLambda * (norm(xk) / norm(Sk))\n",
    "    FLambda0 = FLambda(xk, l0, Sk)\n",
    "    FLambdaPlus = FLambda(xk, l0+deltaL, Sk)\n",
    "    FLambdaMinus = FLambda(xk, l0-deltaL, Sk)\n",
    "    \n",
    "    coef = 0\n",
    "    currentFValue = 0\n",
    "    if FLambda0 < FLambdaPlus and FLambda0 < FLambdaMinus:\n",
    "        print(\"Sven: both Lambdas are increasing funcion\")\n",
    "        return np.array([-deltaL, deltaL])\n",
    "    if FLambda0 > FLambdaPlus and FLambda0 > FLambdaMinus:\n",
    "        raise Exception(\"Sven: both Lambdas are deacreasing function\")\n",
    "    if FLambda0 > FLambdaPlus:\n",
    "        coef = 1\n",
    "        currentFValue = FLambdaPlus\n",
    "        l1 = l0 + coef * deltaL\n",
    "    if FLambda0 > FLambdaMinus:\n",
    "        coef = -1\n",
    "        currentFValue = FLambdaMinus\n",
    "    l1 = l0 + coef * deltaL\n",
    "    currentlValue = l1\n",
    "    lambdaValues = [l0, l1]\n",
    "    FNewLambda = 0\n",
    "    n = 1\n",
    "    while True:\n",
    "        newLambda = currentlValue + 2*n*coef * deltaL\n",
    "        lambdaValues.append(newLambda)\n",
    "        FNewLambda = FLambda(xk, newLambda, Sk)\n",
    "        if (currentFValue < FNewLambda):\n",
    "            break\n",
    "        currentlValue = newLambda\n",
    "        currentFValue = FNewLambda\n",
    "        n = 2*n\n",
    "    print(f\"SVEN - deltaL: {deltaL}, Lambdas: {lambdaValues}, functionCalculatedForLambda: {functionCalculatedForLambda}\")\n",
    "    return np.array([lambdaValues[-3], (lambdaValues[-2] + lambdaValues[-1]) / 2])\n",
    "\n",
    "def goldenCut(lTrustInterval, xk, Sk):\n",
    "    a = lTrustInterval[0]\n",
    "    b = lTrustInterval[1]\n",
    "    biggerCut = (math.sqrt(5) - 1) / 2\n",
    "    smallerCut = 1 - biggerCut\n",
    "    L = b - a\n",
    "    x1 = a + smallerCut * L\n",
    "    x2 = a + biggerCut * L\n",
    "    Fx1 = FLambda(xk, x1, Sk)\n",
    "    Fx2 = FLambda(xk, x2, Sk)\n",
    "\n",
    "    while (L > eGoldenCut):\n",
    "        if Fx1 < Fx2:\n",
    "            b = x2\n",
    "            x2 = x1\n",
    "            L = b - a\n",
    "            x1 = a + smallerCut * L\n",
    "            Fx2 = Fx1\n",
    "            Fx1 = FLambda(xk, x1, Sk)\n",
    "        else:\n",
    "            a = x1\n",
    "            x1 = x2\n",
    "            L = b - a\n",
    "            x2 = a + biggerCut * L\n",
    "            Fx1 = Fx2\n",
    "            Fx2 = FLambda(xk, x2, Sk)\n",
    "    print(f\"GOLDENCUT - INTERVAL: {np.array([x1, x2])}, functionCalculatedForLambda: {functionCalculatedForLambda}\")\n",
    "    return np.array([x1, x2])\n",
    "\n",
    "def DSKPauela():\n",
    "    pass\n",
    "\n",
    "# trustInterval = sven(np.array([-22, -22]), np.array([0, 1]))\n",
    "# print(goldenCut(trustInterval, np.array([-22, -22]), np.array([0, 1])))\n",
    "# print(functionCalculatedForLambda)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITERATION NUMBER 1\n",
      "SVEN - deltaL: 0.5000000000000551, Lambdas: [0, 0.5000000000000551, 1.5000000000001652], functionCalculatedForLambda: 4\n",
      "GOLDENCUT - INTERVAL: [0.5015528100076261 0.5034721887331259], functionCalculatedForLambda: 16\n",
      "Xk+1: [-0.00502499874064144 -0.00502499874064144], Lambda: 0.502512499370376, Fxk: 2, Fxk+1: 5.050122468689611e-05, GradFxk: [-0.010049997481282933 -0.010049997481282933], GradFxk+1: [-0.010049997481282933 -0.010049997481282933]\n",
      "\n",
      "ITERATION NUMBER 2\n",
      "SVEN - deltaL: 0.49999999999999734, Lambdas: [0, 0.49999999999999734, 1.499999999999992], functionCalculatedForLambda: 20\n",
      "GOLDENCUT - INTERVAL: [0.5015528100075681 0.5034721887330679], functionCalculatedForLambda: 32\n",
      "Xk+1: [2.5250612343448615e-05 2.5250612343448615e-05], Lambda: 0.502512499370318, Fxk: 5.050122468689611e-05, Fxk+1: 1.275186847438239e-09, GradFxk: [5.050122468689721e-05 5.050122468689721e-05], GradFxk+1: [5.050122468689721e-05 5.050122468689721e-05]\n",
      "[2.5250612343448615e-05 2.5250612343448615e-05]\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1, 1])\n",
    "\n",
    "h = 0.0001\n",
    "def MOPlconst(e):\n",
    "    xk = x0\n",
    "    l = 1\n",
    "    Fxk = f(xk)\n",
    "    countGrad = True\n",
    "    while True:\n",
    "        if countGrad:\n",
    "            gradFxk = fderright(xk, Fxk, h)# fdercenter(xk, h)\n",
    "        xk_new = xk + l * (-gradFxk / norm(gradFxk))\n",
    "        Fxk_new = f(xk_new)\n",
    "        \n",
    "        print(f'{xk_new}, {l}, {Fxk}, {Fxk_new}')\n",
    "        \n",
    "        if stopCriteria1(xk, Fxk, xk_new, Fxk_new, e):\n",
    "            return xk_new\n",
    "        if (Fxk <= Fxk_new):\n",
    "            # What should I do with L?\n",
    "            l = l / 2\n",
    "            countGrad = False\n",
    "        else: \n",
    "            xk = xk_new\n",
    "            Fxk = Fxk_new\n",
    "            countGrad = True\n",
    "\n",
    "# stopCriteria2(gradFxk, e)\n",
    "def MOPlopt(e):\n",
    "    i = 0\n",
    "    xk = x0\n",
    "    Fxk = f(xk)\n",
    "    gradFxk = fdercenter(xk, h)\n",
    "    while True:\n",
    "        #  fderright(xk, Fxk, h) fdercenter(xk, h)\n",
    "        i += 1\n",
    "        print(f\"\\nITERATION NUMBER {i}\")\n",
    "        Sk = - gradFxk\n",
    "        l = np.mean(goldenCut(sven(xk, Sk), xk, Sk))\n",
    "        xk_new = xk + l * Sk\n",
    "        Fxk_new = f(xk_new)\n",
    "        \n",
    "        oldGrad = gradFxk\n",
    "        gradFxk = fdercenter(xk_new, h)\n",
    "        print(f'Xk+1: {xk_new}, Lambda: {l}, Fxk: {Fxk}, Fxk+1: {Fxk_new}, GradFxk: {gradFxk}, GradFxk+1: {gradFxk}')\n",
    "        \n",
    "        if stopCriteria2(gradFxk, e):\n",
    "            return xk_new\n",
    "        xk = xk_new\n",
    "        Fxk = Fxk_new\n",
    "        \n",
    "\n",
    "print(MOPlopt(0.01))\n",
    "print(functionCalculated)\n",
    "# print(functionCalculatedForLambda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
